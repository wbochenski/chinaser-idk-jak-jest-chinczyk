{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b31bca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    pil_img = Image.fromarray(image)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(pil_img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def preprocess(image):\n",
    "    image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4e898410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicked_points = []\n",
    "_last_H = None\n",
    "\n",
    "# def _on_mouse(event, x, y, flags, param):\n",
    "#     if event == cv2.EVENT_LBUTTONDOWN:\n",
    "#         clicked_points.append((x, y))\n",
    "#         msg = f\"click: ({x}, {y})\"\n",
    "#         # Also print board-space if homography is available\n",
    "#         try:\n",
    "#             if _last_H is not None:\n",
    "#                 H_inv = np.linalg.inv(_last_H)  # camera -> board\n",
    "#                 p = np.array([[[x, y]]], dtype=np.float32)\n",
    "#                 q = cv2.perspectiveTransform(p, H_inv)[0, 0]\n",
    "#                 msg += f\" | board: ({int(q[0])}, {int(q[1])})\"\n",
    "#         except np.linalg.LinAlgError:\n",
    "#             pass\n",
    "#         print(msg)\n",
    "\n",
    "def process_video(file, show=True):\n",
    "    in_path = f\"data/{file}.mp4\"\n",
    "    cap = cv2.VideoCapture(in_path)\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fps = fps if fps and fps > 0 else 25.0\n",
    "    delay_ms = int(1000 / fps)\n",
    "\n",
    "    paused = False\n",
    "    frame_out = None\n",
    "\n",
    "    if show:\n",
    "        cv2.namedWindow(\"video\")\n",
    "        # cv2.setMouseCallback(\"video\", _on_mouse)\n",
    "\n",
    "    while True:\n",
    "        if not paused or frame_out is None:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame_out = pipeline(frame)\n",
    "\n",
    "        # # draw clicked points on the shown frame\n",
    "        # for pt in clicked_points:\n",
    "        #     if 0 <= pt[0] < frame_out.shape[1] and 0 <= pt[1] < frame_out.shape[0]:\n",
    "        #         cv2.circle(frame_out, pt, 5, (0, 255, 0), -1)\n",
    "\n",
    "        if show:\n",
    "            cv2.imshow(\"video\", frame_out)\n",
    "\n",
    "        key = cv2.waitKey(0 if paused else delay_ms) & 0xFF\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "        elif key == ord(\" \"):  # spacebar\n",
    "            paused = not paused\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ec5318f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def process_video(file, show=True, duration_sec=30):\n",
    "    in_path = f\"data/{file}.mp4\"\n",
    "    temp_path = f\"temp_{file}.avi\"\n",
    "    out_path = f\"data/{file}_output.mp4\"\n",
    "    \n",
    "    cap = cv2.VideoCapture(in_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open {in_path}\")\n",
    "        return\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fps = fps if fps and fps > 0 else 25.0\n",
    "    delay_ms = int(1000 / fps)\n",
    "    \n",
    "    total_frames = int(fps * duration_sec)\n",
    "    frame_count = 0\n",
    "\n",
    "    # Use MJPEG codec (more reliable than mp4v)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    out = cv2.VideoWriter(temp_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    if not out.isOpened():\n",
    "        print(\"Error: Cannot open VideoWriter\")\n",
    "        cap.release()\n",
    "        return\n",
    "\n",
    "    paused = False\n",
    "    frame_out = None\n",
    "\n",
    "    if show:\n",
    "        cv2.namedWindow(\"video\")\n",
    "\n",
    "    print(f\"Processing {total_frames} frames...\")\n",
    "    \n",
    "    while frame_count < total_frames:\n",
    "        if not paused or frame_out is None:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame_out = pipeline(frame)\n",
    "            out.write(frame_out)\n",
    "            frame_count += 1\n",
    "\n",
    "        if show:\n",
    "            cv2.imshow(\"video\", frame_out)\n",
    "\n",
    "        key = cv2.waitKey(0 if paused else delay_ms) & 0xFF\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "        elif key == ord(\" \"):\n",
    "            paused = not paused\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(f\"✓ Temp video saved: {temp_path}\")\n",
    "    \n",
    "    # Convert to MP4 with ffmpeg\n",
    "    print(f\"Converting to {out_path}...\")\n",
    "    cmd = [\n",
    "        \"ffmpeg\", \"-i\", temp_path, \n",
    "        \"-c:v\", \"libx264\", \"-crf\", \"23\",\n",
    "        \"-y\", out_path\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        subprocess.run(cmd, check=True, capture_output=True)\n",
    "        print(f\"✓ Video saved: {out_path}\")\n",
    "        os.remove(temp_path)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error: ffmpeg failed - {e.stderr.decode()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "11e0f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_of_board(frame_bgr):\n",
    "    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    mask = cv2.inRange(hsv, np.array([20, 40, 40]), np.array([140, 255, 255]))\n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    filtered = [c for c in contours if cv2.contourArea(c) > 500]\n",
    "    \n",
    "    all_points = np.vstack(filtered)\n",
    "    hull = cv2.convexHull(all_points)\n",
    "    \n",
    "    board_mask = np.zeros_like(mask)\n",
    "    cv2.drawContours(board_mask, [hull], -1, 255, -1)\n",
    "    \n",
    "    return board_mask\n",
    "\n",
    "BOARD_IMG = cv2.imread(\"data/board.jpg\")\n",
    "BOARD_IMG_MASK = get_mask_of_board(BOARD_IMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "be99b971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_features(bgr):\n",
    "    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    gray = clahe.apply(gray)\n",
    "    gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    return gray\n",
    "\n",
    "def find_H(template_bgr, frame_bgr, template_mask=None):\n",
    "    # ORB works best on single-channel images\n",
    "    img1 = preprocess_for_features(template_bgr)\n",
    "    img2 = preprocess_for_features(frame_bgr)\n",
    "\n",
    "    orb = cv2.ORB_create(\n",
    "        nfeatures=6000,\n",
    "        scaleFactor=1.2,\n",
    "        nlevels=8,\n",
    "        fastThreshold=10,\n",
    "    )\n",
    "\n",
    "    k1, d1 = orb.detectAndCompute(img1, template_mask)\n",
    "    k2, d2 = orb.detectAndCompute(img2, None)\n",
    "\n",
    "    if d1 is None or d2 is None or len(k1) < 8 or len(k2) < 8:\n",
    "        return None, 0\n",
    "\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "    matches = bf.knnMatch(d1, d2, k=2)\n",
    "\n",
    "    good = []\n",
    "    for pair in matches:\n",
    "        if len(pair) != 2:\n",
    "            continue\n",
    "        m, n = pair\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    if len(good) < 25:\n",
    "        return None, 0\n",
    "\n",
    "    src = np.float32([k1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "    dst = np.float32([k2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "\n",
    "    # Prefer USAC if available (OpenCV builds vary)\n",
    "    method = cv2.RANSAC\n",
    "    if hasattr(cv2, \"USAC_MAGSAC\"):\n",
    "        method = cv2.USAC_MAGSAC\n",
    "\n",
    "    H, inlier_mask = cv2.findHomography(src, dst, method, 3.0)\n",
    "\n",
    "    if H is None or inlier_mask is None:\n",
    "        return None, 0\n",
    "\n",
    "    inliers = int(inlier_mask.ravel().sum())\n",
    "    \n",
    "    return H, inliers\n",
    "\n",
    "\n",
    "_last_H = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ecb16a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_board(frame, H_use):\n",
    "    points = [(480,590), (3000,570), (2987,3141), (445,3088)]\n",
    "    points_cam = []\n",
    "    center = (1707,1849)\n",
    "    output = frame.copy()\n",
    "    for pt in points:\n",
    "        board_point = np.array([[[pt[0], pt[1]]]], dtype=np.float32)\n",
    "        camera_point = cv2.perspectiveTransform(board_point, H_use)\n",
    "        pt_cam = tuple(map(int, camera_point[0][0]))\n",
    "        points_cam.append(pt_cam)\n",
    "    #draw a box around the board\n",
    "    # put text \"BOARD\" above the box\n",
    "    # cv2.putText(output, \"BOARD\", (points_cam[3][0], points_cam[3][1] - 20), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)\n",
    "    cv2.line(output, points_cam[0], points_cam[1], (255, 0, 0), 5)\n",
    "    cv2.line(output, points_cam[1], points_cam[2], (255, 0, 0), 5)\n",
    "    cv2.line(output, points_cam[2], points_cam[3], (255, 0, 0), 5)\n",
    "    cv2.line(output, points_cam[3], points_cam[0], (255, 0, 0), 5)\n",
    "\n",
    "    board_center = np.array([[[center[0], center[1]]]], dtype=np.float32)\n",
    "    camera_center = cv2.perspectiveTransform(board_center, H_use)\n",
    "    center_cam = tuple(map(int, camera_center[0][0]))\n",
    "    # cv2.circle(output, center_cam, 7, (0, 0, 255), -1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "211c86ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_all_red_areas(frame, H_use):\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (11, 11))\n",
    "\n",
    "    red_mask = cv2.inRange(rgb, np.array([40, 0, 0]), np.array([200, 50, 50]))\n",
    "    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, kernel)\n",
    "    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    green_mask = cv2.inRange(rgb, np.array([0, 40, 0]), np.array([150, 200, 150]))\n",
    "    green_mask = cv2.morphologyEx(green_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    green_mask = cv2.morphologyEx(green_mask, cv2.MORPH_OPEN, kernel)\n",
    "    green_mask = cv2.morphologyEx(green_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    yellow_mask = cv2.inRange(rgb, np.array([40, 0, 0]), np.array([200, 100, 30]))\n",
    "    yellow_mask = cv2.morphologyEx(yellow_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    yellow_mask = cv2.morphologyEx(yellow_mask, cv2.MORPH_OPEN, kernel)\n",
    "    yellow_mask = cv2.morphologyEx(yellow_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    r = 5\n",
    "    board_points = [(1529, 2852), (1524, 2691), (1529, 2517), (1529, 2348), (1538, 2188), (1364, 2179), (1364, 2005), (1194, 2005), (1030, 2009), (856, 2014), (700, 2009), (530, 2001), (535, 1831), (713, 1657), (865, 1662), (1038, 1666), (1199, 1671), (1359, 1662), (1359, 1497), (1542, 1506), (1542, 1332), (1551, 1163), (1542, 1002), (1542, 833), (1556, 664), (1730, 655), (1872, 1501), (1872, 1341), (1881, 1163), (1881, 993), (2037, 1506), (2051, 1671), (2211, 1684), (2394, 1693), (2563, 1693), (2737, 1689), (2907, 1689), (2907, 1689), (2911, 1858), (2911, 2032), (2711, 2032), (2550, 2027), (2394, 2023), (2211, 2023), (2033, 2023), (2037, 2188), (1868, 2183), (1863, 2353), (1868, 2535), (1859, 2682), (1859, 2870), (1863, 3034), (1694, 3052)]\n",
    "\n",
    "    # points_with_mask = []\n",
    "    for pt in board_points:\n",
    "        board_point = np.array([[[pt[0], pt[1]]]], dtype=np.float32)\n",
    "        camera_point = cv2.perspectiveTransform(board_point, H_use)\n",
    "        pt_cam = tuple(map(int, camera_point[0][0]))\n",
    "        x, y = pt_cam\n",
    "        # Create a circular mask around the point\n",
    "        circle_mask = np.zeros_like(red_mask)\n",
    "        cv2.circle(circle_mask, (x, y), r, 255, -1)\n",
    "        \n",
    "        # Check if there's any red mask within the circle\n",
    "        if np.any(cv2.bitwise_and(red_mask, circle_mask)):\n",
    "            cv2.putText(frame, \"RED PIECE\", (x - 40, y - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            cv2.circle(frame, pt_cam, 7, (0, 0, 255), -1)        \n",
    "        elif np.any(cv2.bitwise_and(green_mask, circle_mask)):\n",
    "            cv2.putText(frame, \"GREEN PIECE\", (x - 40, y - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.circle(frame, pt_cam, 7, (0, 255, 0), -1)    \n",
    "        elif np.any(cv2.bitwise_and(yellow_mask, circle_mask)):\n",
    "            cv2.putText(frame, \"YELLOW PIECE\", (x - 40, y - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "            cv2.circle(frame, pt_cam, 7, (0, 255, 255), -1) \n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5a560a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 900 frames...\n",
      "✓ Temp video saved: temp_easy1.avi\n",
      "Converting to data/easy1_output.mp4...\n",
      "✓ Video saved: data/easy1_output.mp4\n"
     ]
    }
   ],
   "source": [
    "def pipeline(frame):\n",
    "    global _last_H\n",
    "    H, inliers = find_H(BOARD_IMG, frame, template_mask=BOARD_IMG_MASK)\n",
    "\n",
    "    if H is not None and inliers >= 30:\n",
    "        _last_H = H\n",
    "    elif _last_H is None:\n",
    "        return frame\n",
    "\n",
    "    H_use = _last_H\n",
    "\n",
    "    # Check if H is invertible before using it\n",
    "    try:\n",
    "        H_inv = np.linalg.inv(H_use)\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"Warning: Singular homography matrix, skipping frame\")\n",
    "        return frame\n",
    "\n",
    "    out_w, out_h = BOARD_IMG.shape[1], BOARD_IMG.shape[0]\n",
    "    rectified = cv2.warpPerspective(frame, H_inv, (out_w, out_h))\n",
    "    frame = mask_all_red_areas(frame, H_use)\n",
    "    frame = draw_board(frame, H_use)\n",
    "    return frame\n",
    "process_video(\"easy1\", show=True, duration_sec=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060dac12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
